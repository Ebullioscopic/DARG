# DARG Project Analysis and Implementation Plan

## Goals
- Understand the DARG research paper (found in refdata/refdata.txt)
- Implement DARG using C++ and Python
- Support CUDA for NVIDIA GPUs and MPS for Mac
- Download required benchmark datasets
- Create visualizations
- Implement inference classes and functions
- Create comprehensive tests
- Complete the DARG project

## Paper Analysis - DARG: Distributed Adaptive Routing Graph

### Core Concept
DARG is a novel multi-layered architecture for high-dimensional approximate nearest neighbor (ANN) search that combines:
- Grid-based spatial partitioning
- Adaptive graph routing
- Local Intrinsic Dimensionality (LID) estimation

### Key Performance Metrics (from paper)
- 1.4ms average query latency
- 94.3% recall@10
- 1050 QPS throughput  
- 16% less memory than HNSW (260MB vs 310MB per 1M vectors)

### Five Core Layers
1. **Local Intrinsic Dimensionality (LID) Layer**: Estimates effective dimensionality using Two-NN estimator
2. **PCA and Vector Augmentation Layer**: Incremental PCA with metadata augmentation
3. **Linkage Cache Layer**: Dynamic routing graph with echo calibration
4. **Vector Routing and Beam Search Layer**: Multi-phase beam search with epsilon-greedy selection
5. **Re-ranking and Calibration Layer**: Conditional echo search and lazy recomputation

### Key Algorithms

#### LID Estimation
```
LID(x) = -1/k * Σ(log(ri(x)/rk(x)))^-1
```

#### Vector Augmentation
```
x* = [x', φ1(x), φ2(x), ..., φm(x)]
```

#### Echo Calibration
```
s(t+1)_ij = α * s(t)_ij + (1-α) * success_score
```

### Benchmark Datasets (from paper)
1. **SIFT1B**: 1B 128-dimensional SIFT descriptors
2. **Deep1B**: 1B 96-dimensional CNN features  
3. **Text2Image1B**: 1B 512-dimensional text-image embeddings
4. **GloVe-1.2M**: 1.2M 300-dimensional word embeddings

### Implementation Architecture
- **C++ Core**: High-performance linear algebra, memory management
- **Python Interface**: Research-friendly API, visualization, testing
- **GPU Support**: CUDA (NVIDIA) and MPS (Mac) acceleration
- **Memory Management**: Memory-mapped files, efficient caching

## Implementation Plan

### Phase 1: Core Infrastructure
1. Platform detection (CUDA/MPS/CPU)
2. C++ core with Python bindings
3. Basic data structures and memory management
4. Configuration system

### Phase 2: Algorithm Implementation  
1. LID estimation layer
2. Incremental PCA with augmentation
3. Dynamic linkage cache
4. Beam search routing
5. Echo search and calibration

### Phase 3: Dataset Integration
1. Download benchmark datasets
2. Data preprocessing pipelines
3. Format standardization

### Phase 4: Inference and Evaluation
1. Query processing interface
2. Performance benchmarking
3. Visualization tools
4. Comprehensive testing

### Phase 5: Optimization
1. GPU acceleration implementation
2. Memory optimization
3. Parallel processing
4. Production deployment features

## Technical Requirements

### Dependencies
- **C++**: Eigen3, Intel MKL, OpenMP
- **Python**: NumPy, SciPy, Matplotlib, pytest
- **GPU**: CUDA Toolkit (NVIDIA), Metal Performance Shaders (Mac)
- **Build**: CMake, pybind11

### Key Parameters (from paper)
- Beam width B = 32
- Projection dimensionality ratio = 0.2-0.4
- Linkage cache size = 64 entries per partition
- Echo trigger threshold = 0.75

## Next Steps
1. Set up development environment
2. Implement platform detection
3. Create C++ core structure
4. Begin with LID estimation layer
5. Download SIFT1B dataset for initial testing
